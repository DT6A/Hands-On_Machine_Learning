{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML11_Distribution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DT6A/Hands-On_Machine_Learning/blob/main/ML11_Distribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovbj0RC4qfo6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxeZrY3Vq0VT"
      },
      "source": [
        "#Multiple devices on a single machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9t8GJPvzliJ"
      },
      "source": [
        "##Placing operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF3s4WdYrHC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "4dfea657-dcab-428d-a8ad-09e5535549ab"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul  1 19:30:43 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    17W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxGZ7pnTrV4s"
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
        "session = tf.Session(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0DTdJpfrjgX"
      },
      "source": [
        "session.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuYxC1SattdU"
      },
      "source": [
        "###Simple placement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWGJSV0eqw9C"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  a = tf.Variable(3.0)\n",
        "  b = tf.constant(4.0)\n",
        "c = a * b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4i6sK9arDDO"
      },
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "a.initializer.run(session=sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLodrBp1r1RN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f60fd6a-4ec0-4e19-c503-96e027f95e56"
      },
      "source": [
        "sess.run(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBZU6oGtsJP4"
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR3WZH_Mty1G"
      },
      "source": [
        "### Dynamic placement function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTk0tC5csK43"
      },
      "source": [
        "def variables_on_cpu(op):\n",
        "  if op.type == 'Variable':\n",
        "    return '/cpu:0'\n",
        "  else:\n",
        "    return '/gpu:0'\n",
        "  \n",
        "with tf.device(variables_on_cpu):\n",
        "  a = tf.Variable(3.0)\n",
        "  b = tf.constant(4.0)\n",
        "  c = a * b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmxxjZw2t42J"
      },
      "source": [
        "### Operations and kernels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg4St016tZ1i"
      },
      "source": [
        "Not all operations have ***kernel*** for GPU!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pukPVhJss_C8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50b7a3c1-d2cf-474b-878e-b5fc523b4dc8"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  i = tf.Variable(3)\n",
        "with tf.Session() as sess:\n",
        "  sess.run(i.initializer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation Variable_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nAssign: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  Variable_2 (VariableV2) /device:GPU:0\n  Variable_2/Assign (Assign) /device:GPU:0\n  Variable_2/read (Identity) /device:GPU:0\n\nOp: VariableV2\nNode attrs: shape=[], shared_name=\"\", dtype=DT_INT32, container=\"\"\nRegistered kernels:\n  device='GPU'; dtype in [DT_INT64]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n\n\t [[{{node Variable_2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-38c49b7a8904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation Variable_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nAssign: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  Variable_2 (VariableV2) /device:GPU:0\n  Variable_2/Assign (Assign) /device:GPU:0\n  Variable_2/read (Identity) /device:GPU:0\n\nOp: VariableV2\nNode attrs: shape=[], shared_name=\"\", dtype=DT_INT32, container=\"\"\nRegistered kernels:\n  device='GPU'; dtype in [DT_INT64]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n\n\t [[node Variable_2 (defined at <ipython-input-10-38c49b7a8904>:2) ]]\n\nOriginal stack trace for 'Variable_2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-38c49b7a8904>\", line 2, in <module>\n    i = tf.Variable(3)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1728, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 79, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1609, in variable_v2\n    shared_name=shared_name, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFtAj20t8VU"
      },
      "source": [
        "### Soft placement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1UUXH8itV9N"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  i = tf.Variable(3)\n",
        "  \n",
        "config = tf.ConfigProto()\n",
        "config.allow_soft_placement = True\n",
        "\n",
        "with tf.Session(config=config) as sess:\n",
        "  sess.run(i.initializer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "396nLSDczqZe"
      },
      "source": [
        "##Control Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf1BJXACuSRY"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "a = tf.constant(1.0)\n",
        "b = a + 2.0\n",
        "\n",
        "with tf.control_dependencies([a, b]):\n",
        "  x = tf.constant(3.0)\n",
        "  y = tf.constant(4.0)\n",
        "  \n",
        "z = x + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_CMaQSQ-VR4"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  z.eval(session=sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDWkj9Og-8kg"
      },
      "source": [
        "#Multiple Devices Across Multiples Servers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhkvB6mN-dSK"
      },
      "source": [
        "cluster_spec = tf.train.ClusterSpec({\n",
        "    'ps':[\n",
        "        'machine-a.example.com:2221', #/job:ps/task:0\n",
        "    ],\n",
        "    'worker':[\n",
        "        'machine-a.example.com:2222', #/job:worker/task:0\n",
        "        'machine-b.example.com:2222', #/job:worker/task:1\n",
        "    ]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i4bPsKwAS0b"
      },
      "source": [
        "server = tf.train.Server(cluster_spec, job_name='worker', task_index=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0sW6KqAAnoX"
      },
      "source": [
        "server.join() # blocks until the server stops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSPXgz4PA-KF"
      },
      "source": [
        "a = tf.constant(1.0)\n",
        "b = a + 2\n",
        "c = a * 3\n",
        "\n",
        "with tf.Session('grpc://machine-b.example.com:2222') as sess:\n",
        "  print(c.eval())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHcJj3XqBlrB"
      },
      "source": [
        "with tf.device('/job:ps/task:0/cpu:0'):\n",
        "  a = tf.constant(1.0)\n",
        "with tf.device('/job:worker/task:0/gpu:1'):\n",
        "  b = a + 2\n",
        "c = a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo9mCYWfC-Vf"
      },
      "source": [
        "# Sharing variables\n",
        "\n",
        "with tf.device(tf.train.replica_device_setter(ps_tasks=2)):\n",
        "  v1 = tf.Variable(1.0) # /job:ps/task:0\n",
        "  v2 = tf.Variable(2.0) # /job:ps/task:1\n",
        "  v3 = tf.Variable(3.0) # /job:ps/task:0\n",
        "  v4 = tf.Variable(4.0) # /job:ps/task:1\n",
        "  v5 = tf.Variable(5.0) # /job:ps/task:0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZIwYNrPnq4C"
      },
      "source": [
        "with tf.device(tf.train.replica_device_setter(ps_tasks=2)):\n",
        "  v1 = tf.Variable(1.0) # /job:ps/task:0 (default /cpu:0)\n",
        "  v2 = tf.Variable(2.0) # /job:ps/task:1 (default /cpu:0)\n",
        "  v3 = tf.Variable(3.0) # /job:ps/task:0 (default /cpu:0)\n",
        "  s = v1 + v2 # /job:worker (default task:0/gpu:0)\n",
        "  with tf.device('/gpu:1'):\n",
        "    p1 = 2 * s # /job:worker/gpu1 (default task:0)\n",
        "    with tf.device('/task:1'):\n",
        "      p2 = 3 * s # /job:worker/task:1/gpu:1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmdiS56cp5Mr"
      },
      "source": [
        "# simple_client.py\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "x = tf.Variable(0.0, name='x')\n",
        "increment_x = tf.assign(x, x + 1)\n",
        "\n",
        "with tf.Session(sys.argv[1]) as sess:\n",
        "  if sys.argv[2:] == ['init']:\n",
        "    sess.run(x.initializer)\n",
        "  sess.run(increment_x)\n",
        "  print(x.eval())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY-rRX_-q8Z6"
      },
      "source": [
        "! python3 simple_client.py grpc://machine-a.example.com:2222 init\n",
        "#outputs 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVR25m1KrT8w"
      },
      "source": [
        "! python3 simple_client.py grpc://machine-b.example.com:2222\n",
        "#outputs 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbCX1NGWrfBz"
      },
      "source": [
        "with tf.container('my_problem_1'):\n",
        "  # Construction phase of problem 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfOa5vNsr5nB"
      },
      "source": [
        "tf.Session().reset('grpc://machine-a.example.com:2222',['my_problem_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFis2C9KsEsk"
      },
      "source": [
        "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name='q', shared_name='shared_q')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yWs38jxtlJc"
      },
      "source": [
        "# training_data_loader.py\n",
        "import tensorflow as tf\n",
        "\n",
        "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name='q', shared_name='shared_q')\n",
        "training_instances = tf.placeholder(tf.float32, shape=[2])\n",
        "enqueue = q.enqueue([training_instances])\n",
        "\n",
        "with tf.Session('grpc://machine-a.example.com:2222') as sess:\n",
        "  sess.run(enqueue, feed_dict={training_instances:[1., 2.]})\n",
        "  sess.run(enqueue, feed_dict={training_instances:[3., 4.]})\n",
        "  sess.run(enqueue, feed_dict={training_instances:[5., 6.]})\n",
        "  \n",
        "training_instances = tf.placeholder(tf.float32, shape=(None, 2))\n",
        "enqueue_many = q.enqueue_many([training_instances])\n",
        "\n",
        "with tf.Session('grpc://machine-a.example.com:2222') as sess:\n",
        "  sess.run(enqueue_many, feed_dict={training_instances: [[1., 2.], [3., 4.], [5., 6.]]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbcxwPUWu_iL"
      },
      "source": [
        "# trainer.py\n",
        "import tensorflow as tf\n",
        "\n",
        "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name='q', shared_name='shared_q')\n",
        "dequeue = q.dequeue()\n",
        "\n",
        "with tf.Session('grpc://machine-a.example.com:2222') as sess:\n",
        "  print(sess.run(dequeue)) # [1., 2.]\n",
        "  print(sess.run(dequeue)) # [3., 4.]\n",
        "  print(sess.run(dequeue)) # [5., 6.]\n",
        "  \n",
        "batch_size = 2\n",
        "dequeue_mini_batch = q.dequeue_many(batch_size)\n",
        "\n",
        "with tf.Session('grpc://machine-a.example.com:2222') as sess:\n",
        "  print(sess.run(dequeue_mini_batch)) # [[1., 2.], [3., 4.]]\n",
        "  print(sess.run(dequeue_mini_batch)) # blocked\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzc5D83bwPK_"
      },
      "source": [
        "q = tf.FIFOQueue(capacity=10, dtypes=[tf.int32, tf.float32], shapes=[[], [3, 2]], name='q', shared_name='shared_q')\n",
        "\n",
        "a = tf.placeholder(tf.int32, shape=())\n",
        "b = tf.placeholder(tf.float32, shape=(3, 2))\n",
        "\n",
        "enqueue = q.enqueue((a, b))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(enqueue, feed_dict={a: 10, b:[[1., 2.], [3., 4.], [5., 6.]]})\n",
        "  \n",
        "dequeue_a, dequeue_b = q.dequeue()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  a_val, b_val = sess.run([dequeue_a, dequeue_b])\n",
        "  print(a_val) # 10\n",
        "  print(b_val) # [[1., 2.], [3., 4.], [5., 6.]]\n",
        "  \n",
        "\n",
        "batch_size = 2\n",
        "dequeue_as, dequeue_bs = q.dequeue_many(batch_size)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  a, b = sess.run([dequeue_as, dequeue_bs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEQK3Aonxp6f"
      },
      "source": [
        "close_q = q.close()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(close_q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LBo1p9nzQqP"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Za7UiJzM_s"
      },
      "source": [
        "training_set_init = tf.placeholder(tf.float32, shape=(None, n_features))\n",
        "training_set = tf.Variable(training_set_init, trainable=False, collections=[], name='training_set')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  data = [...] # load data\n",
        "  sess.run(training_set.initializer, feed_dict={training_set_init: data})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJm9apV0BX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "394fbf62-ee35-4566-ecbd-db9728ab6dd8"
      },
      "source": [
        "reader = tf.TextLineReader(skip_header_lines=1)\n",
        "\n",
        "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
        "filename = tf.placeholder(tf.string)\n",
        "enqueue_filename = filename_queue.enqueue([filename])\n",
        "close_filename_queue = filename_queue.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0702 17:54:39.677659 140615820392320 deprecation.py:323] From <ipython-input-2-cb1935fc0121>:1: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toOO-ngb0wJE"
      },
      "source": [
        "key, value = reader.read(filename_queue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4281KZhN1CQt"
      },
      "source": [
        "x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
        "features = tf.stack([x1, x2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn9pZBRW1cFN"
      },
      "source": [
        "instance_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=2, dtypes=[tf.float32, tf.int32], shapes=[[2], []],\n",
        "                                       name='instance_q', shared_name='shared_instance_q')\n",
        "enqueue_instance = instance_queue.enqueue([features, target])\n",
        "close_instance_queue = instance_queue.close()\n",
        "                                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTCwqhxH2K2t"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(enqueue_filename, feed_dict={filename: 'my_test.csv'})\n",
        "  sess.run(close_filename_queue)\n",
        "  try:\n",
        "    while True:\n",
        "      sess.run(enqueue_instance)\n",
        "  except tf.errors.OutOfRangeError as ex:\n",
        "    pass\n",
        "  sess.run(close_instance_queue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeCr1NpL27-R"
      },
      "source": [
        "instance_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=2, dtypes=[tf.float32, tf.int32], shapes=[[2], []],\n",
        "                                       name='instance_q', shared_name='shared_instance_q')\n",
        "mini_batch_instances, mini_batch_targets = instance_queue.dequeue_up_to(2)\n",
        "\n",
        "[...] # building graph\n",
        "\n",
        "training_op = [...]\n",
        "\n",
        "with tf.Session([...]) as sess:\n",
        "  try:\n",
        "    for step in range(max_steps):\n",
        "      sess.run(training_op)\n",
        "  except tf.errors.OutOfRangeError as ex:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNSHaOGj3nLN"
      },
      "source": [
        "coord = tf.train.Coordinator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34jiVqWh51zO"
      },
      "source": [
        "while not coord.should_stop():\n",
        "  [...] # do something"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXfZqZxd6Cg-"
      },
      "source": [
        "coord.request_stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ocxIwY6FXy"
      },
      "source": [
        "coord.join(list_of_threads)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnwaJ_lV7950"
      },
      "source": [
        "[...] # construction phase\n",
        "queue_runner = tf.train.QueueRunner(instance_queue, [enqueue_instance] * 5)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(enqueue_filename, feed_dict={filename: 'my_test.csv'})\n",
        "  sess.run(close_filename_queue)\n",
        "  coord = tf.train.Coordinator()\n",
        "  enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMzbe4C38-bl"
      },
      "source": [
        "def read_and_push_instance(filename_queue, instance_queue):\n",
        "  reader = tf.TextLineReader(skip_header_lines=1)\n",
        "  key, value = reader.read(filename_queue)\n",
        "  x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
        "  features = tf.stack([x1, x2])\n",
        "  enqueue_instance = instance_queue.enqueue([features, target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmBraJIB90Jc"
      },
      "source": [
        "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
        "filename = tf.placehodler(tf.string)\n",
        "enqueue_filename = filename_queue.enqueue([filename])\n",
        "close_filename_queue = filename_queue.close()\n",
        "instance_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=2, dtypes=[tf.float32, tf.int32], shapes=[[2], []],\n",
        "                                       name='instance_q', shared_name='shared_instance_q')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvxVn_5e-aOc"
      },
      "source": [
        "read_and_enqueue_ops = [\n",
        "    read_and_push_instance(filename_queue, instance_queue)\n",
        "    for i in range(5)]\n",
        "\n",
        "queue_runner = tf.train.QueueRunner(instance_queue, read_and_enqueue_ops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msOngXqx_c6K"
      },
      "source": [
        "#Parallelizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA_XcXDS_eXc"
      },
      "source": [
        "with tf.Session([...]) as sess:\n",
        "  [...]\n",
        "  run_options = tf.RunOptions()\n",
        "  run_options.timeout_in_ms = 1000\n",
        "  try:\n",
        "    pred = sess.run(dequeue_predictions, options=run_options)\n",
        "  except tf.errors.DeadlineExceededError as ex:\n",
        "    [...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwRrmFLoBd7J"
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "config.operation_timeout_in_ms = 1000\n",
        "\n",
        "with tf.Session([...], config=config) as sess:\n",
        "  [...]\n",
        "  try:\n",
        "    pred = sess.run(dequeue_prediction)\n",
        "  except tf.errors.DeadlineExceededError as ex:\n",
        "    [...]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}